# Supported ATen operators and their default inputs
aten._adaptive_avg_pool2d.default: torchbench_train/vgg16_training.txt
aten._adaptive_avg_pool2d_backward.default: torchbench_train/vgg16_training.txt
aten._cudnn_rnn.default: torchbench_train/tts_angular_training.txt
aten._cudnn_rnn_backward.default: torchbench_train/tts_angular_training.txt
aten._embedding_bag.default: torchbench_train/fambench_dlrm_training.txt
aten._embedding_bag_per_sample_weights_backward.default: torchbench_train/fambench_dlrm_training.txt
aten._fft_c2c.default: hf_train/GoogleFnet_training.txt
aten._index_put_impl_.default: torchbench_train/vision_maskrcnn_training.txt
aten._log_softmax.default: torchbench_train/pytorch_struct_training.txt
aten._log_softmax_backward_data.default: torchbench_train/pytorch_struct_training.txt
aten._softmax.default: torchbench_train/timm_vision_transformer_training.txt
aten._softmax_backward_data.default: torchbench_train/timm_vision_transformer_training.txt
aten._sparse_coo_tensor_with_dims_and_tensors.default: torchbench_train/fambench_dlrm_training.txt
aten._to_copy.default: torchbench_train/Super_SloMo_training.txt
aten._unsafe_view.default: torchbench_train/timm_vision_transformer_training.txt
aten.abs.default: torchbench_train/Super_SloMo_training.txt
aten.add.Scalar: torchbench_train/timm_efficientdet_training.txt
aten.add.Tensor: torchbench_train/mobilenet_v3_large_training.txt
aten.add_.Tensor: torchbench_train/mobilenet_v3_large_training.txt
aten.addcmul.default: timm_train/resmlp_12_224_training.txt
aten.addmm.default: torchbench_train/mobilenet_v3_large_training.txt
aten.any.default: torchbench_train/hf_Bart_training.txt
aten.as_strided_.default: timm_train/jx_nest_base_training.txt
aten.avg_pool2d.default: torchbench_train/timm_nfnet_training.txt
aten.avg_pool2d_backward.default: torchbench_train/timm_nfnet_training.txt
aten.bernoulli_.float: timm_train/jx_nest_base_training.txt
aten.bitwise_and.Tensor: torchbench_train/vision_maskrcnn_training.txt
aten.bitwise_not.default: hf_train/DebertaV2ForQuestionAnswering_training.txt
aten.bitwise_xor.Tensor: torchbench_train/fastNLP_Bert_training.txt
aten.bmm.default: torchbench_train/fambench_dlrm_training.txt
aten.cat.default: torchbench_train/fambench_dlrm_training.txt
aten.clamp.default: torchbench_train/vision_maskrcnn_training.txt
aten.clamp_min.default: torchbench_train/tts_angular_training.txt
aten.clone.default: torchbench_train/mobilenet_v3_large_training.txt
aten.col2im.default: timm_train/volo_d1_224_training.txt
aten.col2im_backward.default: timm_train/volo_d1_224_training.txt
aten.constant_pad_nd.default: torchbench_train/timm_nfnet_training.txt
aten.convolution.default: torchbench_train/mobilenet_v3_large_training.txt
aten.convolution_backward.default: torchbench_train/mobilenet_v3_large_training.txt
aten.copy_.default: torchbench_train/mobilenet_v3_large_training.txt
aten.cos.default: hf_train/XLNetLMHeadModel_training.txt
aten.cumsum.default: torchbench_train/hf_Longformer_training.txt
aten.div.Scalar: torchbench_train/mobilenet_v3_large_training.txt
aten.div.Tensor: torchbench_train/mobilenet_v3_large_training.txt
aten.div_.Tensor: torchbench_train/hf_Longformer_training.txt
aten.elu.default: torchbench_train/nvidia_deeprecommender_training.txt
aten.elu_backward.default: torchbench_train/nvidia_deeprecommender_training.txt
aten.embedding.default: torchbench_train/BERT_pytorch_training.txt
aten.embedding_dense_backward.default: torchbench_train/BERT_pytorch_training.txt
aten.eq.Scalar: torchbench_train/BERT_pytorch_training.txt
aten.eq.Tensor: torchbench_train/timm_efficientdet_training.txt
aten.erf.default: torchbench_train/fastNLP_Bert_training.txt
aten.exp.default: torchbench_train/vision_maskrcnn_training.txt
aten.fill_.Scalar: torchbench_train/vision_maskrcnn_training.txt
aten.fill_.Tensor: torchbench_train/speech_transformer_training.txt
aten.flip.default: torchbench_train/hf_Longformer_training.txt
aten.floor.default: torchbench_train/vision_maskrcnn_training.txt
aten.floor_divide.default: torchbench_train/timm_efficientdet_training.txt
aten.fmod.Scalar: torchbench_train/fastNLP_Bert_training.txt
aten.gather.default: torchbench_train/fambench_dlrm_training.txt
aten.ge.Scalar: torchbench_train/vision_maskrcnn_training.txt
aten.gelu.default: torchbench_train/timm_nfnet_training.txt
aten.gelu_backward.default: torchbench_train/timm_nfnet_training.txt
aten.grid_sampler_2d.default: torchbench_train/Super_SloMo_training.txt
aten.grid_sampler_2d_backward.default: torchbench_train/Super_SloMo_training.txt
aten.gt.Scalar: torchbench_train/BERT_pytorch_training.txt
aten.gt.Tensor: torchbench_train/timm_efficientdet_training.txt
aten.hardsigmoid.default: torchbench_train/mobilenet_v3_large_training.txt
aten.hardsigmoid_backward.default: torchbench_train/mobilenet_v3_large_training.txt
aten.hardswish.default: timm_train/levit_128_training.txt
aten.hardswish_.default: torchbench_train/mobilenet_v3_large_training.txt
aten.hardswish_backward.default: torchbench_train/mobilenet_v3_large_training.txt
aten.hardtanh.default: timm_train/rexnet_100_training.txt
aten.hardtanh_.default: torchbench_train/mobilenet_v2_training.txt
aten.hardtanh_backward.default: torchbench_train/mobilenet_v2_training.txt
aten.im2col.default: hf_train/YituTechConvBert_training.txt
aten.im2col_backward.default: hf_train/YituTechConvBert_training.txt
aten.index.Tensor: torchbench_train/fambench_dlrm_training.txt
aten.index_add.default: torchbench_train/hf_BigBird_training.txt
aten.index_add_.default: torchbench_train/hf_Longformer_training.txt
aten.index_put.default: torchbench_train/fambench_dlrm_training.txt
aten.index_put_.default: torchbench_train/vision_maskrcnn_training.txt
aten.index_select.default: torchbench_train/fambench_dlrm_training.txt
aten.isinf.default: torchbench_train/hf_Bart_training.txt
aten.isnan.default: torchbench_train/hf_Bart_training.txt
aten.le.Scalar: torchbench_train/vision_maskrcnn_training.txt
aten.leaky_relu.default: torchbench_train/Super_SloMo_training.txt
aten.leaky_relu_.default: torchbench_train/yolov3_training.txt
aten.leaky_relu_backward.default: torchbench_train/Super_SloMo_training.txt
aten.lift_fresh_copy.default: timm_train/cspdarknet53_training.txt
aten.log2.default: torchbench_train/vision_maskrcnn_training.txt
aten.logical_and_.default: torchbench_train/vision_maskrcnn_training.txt
aten.lt.Scalar: torchbench_train/speech_transformer_training.txt
aten.lt.Tensor: torchbench_train/hf_Bart_training.txt
aten.masked_fill.Scalar: torchbench_train/BERT_pytorch_training.txt
aten.masked_fill.Tensor: torchbench_train/hf_DistilBert_training.txt
aten.masked_fill_.Scalar: torchbench_train/BERT_pytorch_training.txt
aten.max.default: torchbench_train/vision_maskrcnn_training.txt
aten.max.dim: timm_train/volo_d1_224_training.txt
aten.max_pool2d_with_indices.default: torchbench_train/Super_SloMo_training.txt
aten.max_pool2d_with_indices_backward.default: torchbench_train/Super_SloMo_training.txt
aten.maximum.default: hf_train/OPTForCausalLM_training.txt
aten.mean.default: torchbench_train/Super_SloMo_training.txt
aten.mean.dim: torchbench_train/mobilenet_v3_large_training.txt
aten.min.default: torchbench_train/vision_maskrcnn_training.txt
aten.minimum.default: torchbench_train/vision_maskrcnn_training.txt
aten.mm.default: torchbench_train/mobilenet_v3_large_training.txt
aten.mse_loss.default: torchbench_train/Super_SloMo_training.txt
aten.mse_loss_backward.default: torchbench_train/Super_SloMo_training.txt
aten.mul.Scalar: torchbench_train/BERT_pytorch_training.txt
aten.mul.Tensor: torchbench_train/mobilenet_v3_large_training.txt
aten.mul_.Tensor: torchbench_train/timm_nfnet_training.txt
aten.native_batch_norm.default: torchbench_train/mobilenet_v3_large_training.txt
aten.native_batch_norm_backward.default: torchbench_train/mobilenet_v3_large_training.txt
aten.native_group_norm.default: timm_train/poolformer_m36_training.txt
aten.native_group_norm_backward.default: timm_train/poolformer_m36_training.txt
aten.native_layer_norm.default: torchbench_train/timm_vision_transformer_training.txt
aten.native_layer_norm_backward.default: torchbench_train/timm_vision_transformer_training.txt
aten.ne.Scalar: torchbench_train/speech_transformer_training.txt
aten.neg.default: torchbench_train/Super_SloMo_training.txt
aten.new_empty.default: torchbench_train/vision_maskrcnn_training.txt
aten.new_empty_strided.default: torchbench_train/pytorch_CycleGAN_and_pix2pix_training.txt
aten.new_full.default: torchbench_train/vision_maskrcnn_training.txt
aten.new_ones.default: torchbench_train/speech_transformer_training.txt
aten.new_zeros.default: torchbench_train/pytorch_CycleGAN_and_pix2pix_training.txt
aten.nll_loss_backward.default: hf_train/ElectraForCausalLM_training.txt
aten.nll_loss_forward.default: hf_train/ElectraForCausalLM_training.txt
aten.nonzero.default: torchbench_train/vision_maskrcnn_training.txt
aten.norm.ScalarOpt_dim: torchbench_train/tts_angular_training.txt
aten.pow.Scalar: hf_train/XLNetLMHeadModel_training.txt
aten.pow.Tensor_Scalar: torchbench_train/hf_Albert_training.txt
aten.reciprocal.default: torchbench_train/vision_maskrcnn_training.txt
aten.reflection_pad2d.default: torchbench_train/pytorch_CycleGAN_and_pix2pix_training.txt
aten.reflection_pad2d_backward.default: torchbench_train/pytorch_CycleGAN_and_pix2pix_training.txt
aten.relu.default: torchbench_train/mobilenet_v3_large_training.txt
aten.relu_.default: torchbench_train/mobilenet_v3_large_training.txt
aten.remainder.Scalar: torchbench_train/timm_efficientdet_training.txt
aten.repeat.default: torchbench_train/BERT_pytorch_training.txt
aten.roll.default: timm_train/swin_base_patch4_window7_224_training.txt
aten.round.default: torchbench_train/vision_maskrcnn_training.txt
aten.rsqrt.default: torchbench_train/vision_maskrcnn_training.txt
aten.rsub.Scalar: torchbench_train/Super_SloMo_training.txt
aten.scatter.src: timm_train/volo_d1_224_training.txt
aten.scatter_add.default: torchbench_train/fambench_dlrm_training.txt
aten.scatter_add_.default: torchbench_train/timm_efficientdet_training.txt
aten.select_backward.default: torchbench_train/Super_SloMo_training.txt
aten.sgn.default: torchbench_train/Super_SloMo_training.txt
aten.sigmoid.default: torchbench_train/timm_nfnet_training.txt
aten.sigmoid_.default: torchbench_train/yolov3_training.txt
aten.sigmoid_backward.default: torchbench_train/timm_nfnet_training.txt
aten.silu.default: timm_train/gmixer_24_224_training.txt
aten.silu_.default: torchbench_train/timm_efficientdet_training.txt
aten.silu_backward.default: torchbench_train/timm_efficientdet_training.txt
aten.sin.default: hf_train/XLNetLMHeadModel_training.txt
aten.slice_backward.default: torchbench_train/fambench_dlrm_training.txt
aten.split.Tensor: torchbench_train/shufflenet_v2_x1_0_training.txt
aten.split_with_sizes.default: torchbench_train/vision_maskrcnn_training.txt
aten.sqrt.default: torchbench_train/vision_maskrcnn_training.txt
aten.stack.default: torchbench_train/Super_SloMo_training.txt
aten.std.correction: torchbench_train/BERT_pytorch_training.txt
aten.sub.Tensor: torchbench_train/Super_SloMo_training.txt
aten.sum.SymInt: torchbench_train/mobilenet_v3_large_training.txt
aten.sum.default: torchbench_train/mobilenet_v3_large_training.txt
aten.sum.dim_IntList: torchbench_train/timm_resnest_training.txt
aten.tanh.default: torchbench_train/pytorch_CycleGAN_and_pix2pix_training.txt
aten.tanh_backward.default: torchbench_train/pytorch_CycleGAN_and_pix2pix_training.txt
aten.threshold_backward.default: torchbench_train/mobilenet_v3_large_training.txt
aten.topk.default: torchbench_train/vision_maskrcnn_training.txt
aten.tril.default: torchbench_train/hf_Longformer_training.txt
aten.triu.default: torchbench_train/speech_transformer_training.txt
aten.unbind.int: torchbench_train/Super_SloMo_training.txt
aten.unfold_backward.default: timm_train/eca_halonext26ts_training.txt
aten.unsqueeze_.default: torchbench_train/hf_BigBird_training.txt
aten.upsample_bicubic2d.vec: timm_train/crossvit_9_240_training.txt
aten.upsample_bilinear2d.vec: torchbench_train/Super_SloMo_training.txt
aten.upsample_bilinear2d_backward.vec: torchbench_train/Super_SloMo_training.txt
aten.upsample_nearest2d.vec: torchbench_train/vision_maskrcnn_training.txt
aten.upsample_nearest2d_backward.vec: torchbench_train/vision_maskrcnn_training.txt
aten.var_mean.correction: timm_train/convnext_base_training.txt
aten.where.self: torchbench_train/vision_maskrcnn_training.txt
